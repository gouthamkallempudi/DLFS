{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ecb18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch \n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nn\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79c40568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inpyt image size\n",
    "ISIZE = (800, 800)\n",
    "\n",
    "# Imagenet statistics\n",
    "imagenet_stats = np.array([[0.485, 0.456, 0.406] , [0.229, 0.224, 0.225]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7618938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def normalize(im):\n",
    "    # convert image to float \n",
    "    im = im / 255.\n",
    "    \"\"\" Normalize with image net stats\"\"\"\n",
    "    return (im - imagenet_stats[0])/imagenet_stats[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad7f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data set and tranforms\n",
    "\n",
    "class PennFudanDataset(Object):\n",
    "    def __init__(self, root, transforms):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        # load all the image files, sorting them to ensure they are aligned\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"PNGImages\"))))\n",
    "        self.masks = list(sorted(os.listdir(os.path.join(root, \"PedMasks\"))))\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # load image and masks\n",
    "        img_path = os.path.join(self.root, \"PNGImages\", self.imgs[idx])\n",
    "        mask_path = os.path.join(self.root, \"PedMasks\" , self.masks[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = img.resize(ISIZE)\n",
    "        img = np.array(img)\n",
    "        img = normalize(img)\n",
    "        img = img.transpose(2,0,1)\n",
    "        img = torch.as_tensor(img, dtype = torch.float32)\n",
    "        \n",
    "        mask = Image.open(mask_path)\n",
    "        mask = mask.resize(ISIZE)\n",
    "        mask = np.array(mask)\n",
    "        obj_ids = np.unique(mask)            # instances are encoded as different colors (0--backhroung)\n",
    "        obj_ids = obj_ids[1:]                # first id is background remove it\n",
    "        # split the color-encoded mask into a set of binary masks (i.e true or false)\n",
    "        masks = mask == obj_ids[:, None, None]\n",
    "        \n",
    "        # get bounding box coordinates for each mask\n",
    "        num_objs = len(obj_ids)\n",
    "        boxes = []\n",
    "\n",
    "        for i in range(num_objs):\n",
    "            pos = np.where(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "            \n",
    "        # convert to torch tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype = torch.float32)   # box dims\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)       # true or false\n",
    "        labels = torch.ones((num_objs,) , dtype = torch.int64)  # no od persons\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])   # area\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        \n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
